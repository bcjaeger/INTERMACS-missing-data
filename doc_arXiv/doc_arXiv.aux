\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{benjamin2017heart}
\citation{national2017health}
\citation{patel2014contemporary}
\citation{slaughter2009advanced}
\citation{miller2011left}
\citation{stewart2011keeping}
\citation{patel2014contemporary}
\citation{hsich2012should}
\citation{cotts2014predictors}
\citation{eckman2011survival}
\citation{kirklin2017eighth}
\citation{kormos2019society}
\citation{Adamo950}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\newlabel{introduction}{{1}{2}{Introduction}{section.1}{}}
\newlabel{sec:introduction}{{1}{2}{Introduction}{section.1}{}}
\@LN{0}{1}
\@LN{1}{1}
\@LN{2}{1}
\@LN{3}{1}
\@LN{4}{1}
\@LN{5}{1}
\@LN{6}{1}
\@LN{7}{1}
\@LN{8}{1}
\@LN{9}{1}
\@LN{10}{1}
\@LN{11}{1}
\@LN{12}{1}
\@LN{13}{1}
\@LN{14}{1}
\@LN{15}{1}
\@LN{16}{1}
\@LN{17}{1}
\@LN{18}{1}
\@LN{19}{1}
\@LN{20}{1}
\@LN{21}{1}
\@LN{22}{1}
\@LN{23}{1}
\@LN{24}{1}
\@LN{25}{1}
\@LN{26}{1}
\@LN{27}{1}
\@LN{28}{1}
\@LN{29}{1}
\citation{rubin2004multiple}
\citation{van2018flexible}
\citation{sterne2009multiple}
\citation{van2020rebutting}
\citation{hastie2009elements}
\citation{kuhn2019feature}
\citation{jerez2010missing}
\citation{josse2019consistency}
\@LN{30}{2}
\@writefile{toc}{\contentsline {section}{\numberline {2}Methods}{3}{section.2}\protected@file@percent }
\newlabel{methods}{{2}{3}{Methods}{section.2}{}}
\newlabel{sec:methods}{{2}{3}{Methods}{section.2}{}}
\@LN{31}{2}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}INTERMACS Registry}{3}{subsection.2.1}\protected@file@percent }
\newlabel{intermacs-registry}{{2.1}{3}{INTERMACS Registry}{subsection.2.1}{}}
\newlabel{subsec:intermacs}{{2.1}{3}{INTERMACS Registry}{subsection.2.1}{}}
\@LN{32}{2}
\@LN{33}{2}
\@LN{34}{2}
\@LN{35}{2}
\@LN{36}{2}
\@LN{37}{2}
\@LN{38}{2}
\@LN{39}{2}
\@LN{40}{2}
\@LN{41}{2}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Outcomes and Predictors}{3}{subsection.2.2}\protected@file@percent }
\newlabel{outcomes-and-predictors}{{2.2}{3}{Outcomes and Predictors}{subsection.2.2}{}}
\@LN{42}{2}
\@LN{43}{2}
\@LN{44}{2}
\@LN{45}{2}
\@LN{46}{2}
\@LN{47}{2}
\@LN{48}{2}
\@LN{49}{2}
\@LN{50}{2}
\@LN{51}{2}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Statistical Inference and Learning with Missing data}{3}{subsection.2.3}\protected@file@percent }
\newlabel{statistical-inference-and-learning-with-missing-data}{{2.3}{3}{Statistical Inference and Learning with Missing data}{subsection.2.3}{}}
\newlabel{subsec:inference_and_learning}{{2.3}{3}{Statistical Inference and Learning with Missing data}{subsection.2.3}{}}
\@writefile{toc}{\contentsline {paragraph}{Statistical Inference}{3}{section*.1}\protected@file@percent }
\@LN{52}{2}
\@LN{53}{2}
\@LN{54}{2}
\@LN{55}{2}
\@LN{56}{2}
\@LN{57}{2}
\@LN{58}{2}
\@LN{59}{2}
\citation{thomas2014pre}
\citation{rubin2004multiple}
\citation{azur2011multiple}
\citation{van2018flexible}
\citation{van2006fully}
\@writefile{toc}{\contentsline {paragraph}{Statistical Learning}{4}{section*.2}\protected@file@percent }
\@LN{60}{3}
\@LN{61}{3}
\@LN{62}{3}
\@LN{63}{3}
\@LN{64}{3}
\@LN{65}{3}
\@LN{66}{3}
\@LN{67}{3}
\@LN{68}{3}
\@writefile{toc}{\contentsline {paragraph}{Using outcomes during imputation}{4}{section*.3}\protected@file@percent }
\@LN{69}{3}
\@LN{70}{3}
\@LN{71}{3}
\@LN{72}{3}
\@LN{73}{3}
\@LN{74}{3}
\@LN{75}{3}
\@LN{76}{3}
\@LN{77}{3}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Missing Data Strategies}{4}{subsection.2.4}\protected@file@percent }
\newlabel{missing-data-strategies}{{2.4}{4}{Missing Data Strategies}{subsection.2.4}{}}
\newlabel{subsec:imputation}{{2.4}{4}{Missing Data Strategies}{subsection.2.4}{}}
\@writefile{toc}{\contentsline {paragraph}{Single and multiple imputation}{4}{section*.4}\protected@file@percent }
\@LN{78}{3}
\@LN{79}{3}
\@LN{80}{3}
\@LN{81}{3}
\@LN{82}{3}
\@LN{83}{3}
\@LN{84}{3}
\@LN{85}{3}
\@writefile{toc}{\contentsline {paragraph}{Imputation to the mean}{4}{section*.5}\protected@file@percent }
\@LN{86}{3}
\@LN{87}{3}
\@LN{88}{3}
\@LN{89}{3}
\@LN{90}{3}
\@LN{91}{3}
\citation{landerman1997empirical}
\citation{chen2000nearest}
\citation{gower}
\citation{andridge2010hotdeck}
\citation{Breiman2001}
\citation{hothorn2006survival}
\citation{strobl2007bias}
\citation{strobl2008conditional}
\citation{ishwaran2008random}
\citation{jaeger2019oblique}
\citation{twala2009empirical}
\citation{ding2010investigation}
\@writefile{toc}{\contentsline {paragraph}{Bayesian Regression}{5}{section*.6}\protected@file@percent }
\@LN{92}{4}
\@LN{93}{4}
\@LN{94}{4}
\@LN{95}{4}
\@LN{96}{4}
\@writefile{toc}{\contentsline {paragraph}{Predictive Mean Matching (PMM)}{5}{section*.7}\protected@file@percent }
\@LN{97}{4}
\@LN{98}{4}
\@LN{99}{4}
\@LN{100}{4}
\@LN{101}{4}
\@LN{102}{4}
\@writefile{toc}{\contentsline {paragraph}{K-Nearest-Neighbors (KNN)}{5}{section*.8}\protected@file@percent }
\@LN{103}{4}
\@LN{104}{4}
\@LN{105}{4}
\@LN{106}{4}
\@LN{107}{4}
\@LN{108}{4}
\@writefile{toc}{\contentsline {paragraph}{Hot Deck}{5}{section*.9}\protected@file@percent }
\@LN{109}{4}
\@LN{110}{4}
\@LN{111}{4}
\@LN{112}{4}
\@LN{113}{4}
\@writefile{toc}{\contentsline {paragraph}{Random forests}{5}{section*.10}\protected@file@percent }
\@LN{114}{4}
\@LN{115}{4}
\@LN{116}{4}
\@LN{117}{4}
\@LN{118}{4}
\@LN{119}{4}
\@LN{120}{4}
\@LN{121}{4}
\@LN{122}{4}
\@writefile{toc}{\contentsline {paragraph}{Missingness incorporated as an attribute (MIA)}{6}{section*.11}\protected@file@percent }
\@LN{123}{5}
\@LN{124}{5}
\@LN{125}{5}
\@LN{126}{5}
\@LN{127}{5}
\@LN{128}{5}
\@LN{129}{5}
\@LN{130}{5}
\@writefile{toc}{\contentsline {paragraph}{Assumptions}{6}{section*.12}\protected@file@percent }
\@LN{131}{5}
\@LN{132}{5}
\@LN{133}{5}
\@LN{134}{5}
\@LN{135}{5}
\@LN{136}{5}
\@LN{137}{5}
\@LN{138}{5}
\@LN{139}{5}
\@LN{140}{5}
\@LN{141}{5}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Evaluating Imputation Accuracy}{6}{subsection.2.5}\protected@file@percent }
\newlabel{evaluating-imputation-accuracy}{{2.5}{6}{Evaluating Imputation Accuracy}{subsection.2.5}{}}
\newlabel{subsec:imputation_accuracy}{{2.5}{6}{Evaluating Imputation Accuracy}{subsection.2.5}{}}
\@LN{142}{5}
\@LN{143}{5}
\@LN{144}{5}
\@LN{145}{5}
\@LN{146}{5}
\@LN{147}{5}
\@LN{148}{5}
\@LN{149}{5}
\@LN{150}{5}
\@LN{151}{5}
\citation{james2013introduction}
\citation{kleinbaum2010survival}
\citation{friedman2001greedy}
\citation{chen2016xgboost}
\citation{graf1999assessment}
\citation{rufibach2010use}
\citation{gerds2006consistent}
\citation{blackstone1986decomposition}
\@LN{152}{6}
\@LN{153}{6}
\@LN{154}{6}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Risk Prediction Models}{7}{subsection.2.6}\protected@file@percent }
\newlabel{risk-prediction-models}{{2.6}{7}{Risk Prediction Models}{subsection.2.6}{}}
\newlabel{subsec:modeling}{{2.6}{7}{Risk Prediction Models}{subsection.2.6}{}}
\@LN{155}{6}
\@LN{156}{6}
\@LN{157}{6}
\@LN{158}{6}
\@LN{159}{6}
\@LN{160}{6}
\@LN{161}{6}
\@LN{162}{6}
\@LN{163}{6}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}Evaluation of Predictions}{7}{subsection.2.7}\protected@file@percent }
\newlabel{evaluation-of-predictions}{{2.7}{7}{Evaluation of Predictions}{subsection.2.7}{}}
\newlabel{subsec:evaluation}{{2.7}{7}{Evaluation of Predictions}{subsection.2.7}{}}
\@writefile{toc}{\contentsline {paragraph}{The Brier score}{7}{section*.13}\protected@file@percent }
\@LN{164}{6}
\@LN{165}{6}
\@LN{166}{6}
\@LN{167}{6}
\newlabel{eqn:brier_score}{{1}{7}{The Brier score}{equation.2.1}{}}
\@LN{168}{6}
\@LN{169}{6}
\@LN{170}{6}
\@LN{171}{6}
\@LN{172}{6}
\@LN{173}{6}
\@writefile{toc}{\contentsline {paragraph}{The scaled Brier score}{7}{section*.14}\protected@file@percent }
\@LN{174}{6}
\@LN{175}{6}
\@LN{176}{6}
\citation{gerds2014calibration}
\citation{gerds2013estimating}
\citation{kuhn2013applied}
\citation{benavoli2017time}
\@LN{177}{7}
\@LN{178}{7}
\@LN{179}{7}
\@LN{180}{7}
\@LN{181}{7}
\@writefile{toc}{\contentsline {paragraph}{Discrimination and calibration}{8}{section*.15}\protected@file@percent }
\@LN{182}{7}
\@LN{183}{7}
\@LN{184}{7}
\@LN{185}{7}
\@LN{186}{7}
\@LN{187}{7}
\@LN{188}{7}
\@LN{189}{7}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8}Internal Validation via Monte-Carlo Cross-Validation (MCCV)}{8}{subsection.2.8}\protected@file@percent }
\newlabel{internal-validation-via-monte-carlo-cross-validation-mccv}{{2.8}{8}{Internal Validation via Monte-Carlo Cross-Validation (MCCV)}{subsection.2.8}{}}
\newlabel{subsec:internal}{{2.8}{8}{Internal Validation via Monte-Carlo Cross-Validation (MCCV)}{subsection.2.8}{}}
\@LN{190}{7}
\@LN{191}{7}
\@LN{192}{7}
\@LN{193}{7}
\@LN{194}{7}
\@LN{195}{7}
\@writefile{toc}{\contentsline {paragraph}{Steps taken in each replicate}{8}{section*.16}\protected@file@percent }
\@LN{196}{7}
\@LN{197}{7}
\@LN{198}{7}
\@LN{199}{7}
\@LN{200}{7}
\@LN{201}{7}
\@LN{202}{7}
\@LN{203}{7}
\@LN{204}{7}
\@LN{205}{7}
\@LN{206}{7}
\@LN{207}{7}
\@LN{208}{7}
\citation{lex2014upset}
\citation{van1995python}
\citation{sas2013}
\citation{drake}
\citation{naniar}
\citation{mice}
\citation{miceRanger}
\citation{table.glue}
\citation{tidyverse}
\citation{rstanarm}
\citation{tidybayes}
\citation{survival}
\citation{tidymodels}
\citation{riskRegression}
\citation{byron_2020_4247449}
\citation{cheaha}
\@writefile{toc}{\contentsline {paragraph}{Bayesian analysis of model performance}{9}{section*.17}\protected@file@percent }
\@LN{209}{8}
\@LN{210}{8}
\@LN{211}{8}
\@LN{212}{8}
\@LN{213}{8}
\@LN{214}{8}
\@LN{215}{8}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9}Statistical analysis}{9}{subsection.2.9}\protected@file@percent }
\newlabel{statistical-analysis}{{2.9}{9}{Statistical analysis}{subsection.2.9}{}}
\@LN{216}{8}
\@LN{217}{8}
\@LN{218}{8}
\@LN{219}{8}
\@LN{220}{8}
\@LN{221}{8}
\@LN{222}{8}
\@LN{223}{8}
\@LN{224}{8}
\@LN{225}{8}
\@LN{226}{8}
\@LN{227}{8}
\@LN{228}{8}
\@LN{229}{8}
\@LN{230}{8}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.10}Computational Details}{9}{subsection.2.10}\protected@file@percent }
\newlabel{computational-details}{{2.10}{9}{Computational Details}{subsection.2.10}{}}
\newlabel{subsec:computing}{{2.10}{9}{Computational Details}{subsection.2.10}{}}
\@LN{231}{8}
\@LN{232}{8}
\@LN{233}{8}
\@LN{234}{8}
\@LN{235}{8}
\@LN{236}{8}
\@LN{237}{8}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{9}{section.3}\protected@file@percent }
\newlabel{results}{{3}{9}{Results}{section.3}{}}
\@writefile{toc}{\contentsline {paragraph}{Patient Characteristics}{9}{section*.18}\protected@file@percent }
\@LN{238}{8}
\@LN{239}{8}
\@LN{240}{9}
\@LN{241}{9}
\@writefile{toc}{\contentsline {paragraph}{Missing data}{10}{section*.19}\protected@file@percent }
\@LN{242}{9}
\@LN{243}{9}
\@LN{244}{9}
\@LN{245}{9}
\@LN{246}{9}
\@writefile{toc}{\contentsline {paragraph}{Imputation accuracy}{10}{section*.20}\protected@file@percent }
\@LN{247}{9}
\@LN{248}{9}
\@LN{249}{9}
\@LN{250}{9}
\@LN{251}{9}
\@LN{252}{9}
\@LN{253}{9}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Scaled Brier score}{10}{subsection.3.1}\protected@file@percent }
\newlabel{scaled-brier-score}{{3.1}{10}{Scaled Brier score}{subsection.3.1}{}}
\@writefile{toc}{\contentsline {paragraph}{Mortality risk prediction}{10}{section*.21}\protected@file@percent }
\@LN{254}{9}
\@LN{255}{9}
\@LN{256}{9}
\@LN{257}{9}
\@LN{258}{9}
\@LN{259}{9}
\@LN{260}{9}
\@writefile{toc}{\contentsline {paragraph}{Transplant risk prediction}{10}{section*.22}\protected@file@percent }
\@LN{261}{9}
\@LN{262}{9}
\@LN{263}{9}
\@LN{264}{9}
\@LN{265}{9}
\@LN{266}{9}
\@LN{267}{9}
\@LN{268}{9}
\@LN{269}{10}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Discrimination and calibration}{11}{subsection.3.2}\protected@file@percent }
\newlabel{discrimination-and-calibration}{{3.2}{11}{Discrimination and calibration}{subsection.3.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Mortality risk prediction}{11}{section*.23}\protected@file@percent }
\@LN{270}{10}
\@LN{271}{10}
\@LN{272}{10}
\@LN{273}{10}
\@LN{274}{10}
\@LN{275}{10}
\@LN{276}{10}
\@writefile{toc}{\contentsline {paragraph}{Transplant risk prediction}{11}{section*.24}\protected@file@percent }
\@LN{277}{10}
\@LN{278}{10}
\@LN{279}{10}
\@LN{280}{10}
\@LN{281}{10}
\@LN{282}{10}
\@LN{283}{10}
\@LN{284}{10}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Bayesian analysis of model performance}{11}{subsection.3.3}\protected@file@percent }
\newlabel{bayesian-analysis-of-model-performance}{{3.3}{11}{Bayesian analysis of model performance}{subsection.3.3}{}}
\@LN{285}{10}
\@LN{286}{10}
\@LN{287}{10}
\@LN{288}{10}
\@LN{289}{10}
\@LN{290}{10}
\@LN{291}{10}
\@LN{292}{10}
\@LN{293}{10}
\@LN{294}{10}
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion}{11}{section.4}\protected@file@percent }
\newlabel{discussion}{{4}{11}{Discussion}{section.4}{}}
\@LN{295}{10}
\@LN{296}{10}
\@LN{297}{10}
\@LN{298}{10}
\@LN{299}{10}
\@LN{300}{10}
\citation{hsich2012should}
\citation{cotts2014predictors}
\citation{eckman2011survival}
\citation{kirklin2017eighth}
\citation{kormos2019society}
\citation{Adamo950}
\citation{josse2019consistency}
\citation{hassan2007regression}
\citation{nanni2012classifier}
\citation{jerez2010missing}
\citation{tutz2015improved}
\citation{little2013joys}
\citation{steele2018machine}
\@LN{301}{11}
\@LN{302}{11}
\@LN{303}{11}
\@LN{304}{11}
\@LN{305}{11}
\@LN{306}{11}
\@LN{307}{11}
\@LN{308}{11}
\@LN{309}{11}
\@LN{310}{11}
\@LN{311}{11}
\@LN{312}{11}
\@LN{313}{11}
\@LN{314}{11}
\@LN{315}{11}
\@LN{316}{11}
\@LN{317}{11}
\@LN{318}{11}
\@LN{319}{11}
\@LN{320}{11}
\@LN{321}{11}
\@LN{322}{11}
\@LN{323}{11}
\@LN{324}{11}
\@LN{325}{11}
\@LN{326}{11}
\@LN{327}{11}
\@LN{328}{11}
\@LN{329}{11}
\@LN{330}{11}
\@LN{331}{11}
\@writefile{toc}{\contentsline {paragraph}{Strengths and limitations}{12}{section*.25}\protected@file@percent }
\@LN{332}{11}
\@LN{333}{11}
\@LN{334}{11}
\@LN{335}{12}
\@LN{336}{12}
\@LN{337}{12}
\@LN{338}{12}
\@LN{339}{12}
\@LN{340}{12}
\@LN{341}{12}
\@LN{342}{12}
\@LN{343}{12}
\@LN{344}{12}
\@LN{345}{12}
\@writefile{toc}{\contentsline {paragraph}{Conclusion}{13}{section*.26}\protected@file@percent }
\@LN{346}{12}
\@LN{347}{12}
\@LN{348}{12}
\@LN{349}{12}
\@LN{350}{12}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Participant characteristics stratified by event status. The majority of patients were male and nearly all mechanical circulatory support devices were left-ventricular assistance devices.}}{14}{table.1}\protected@file@percent }
\newlabel{tbl_characteristics}{{1}{14}{Participant characteristics stratified by event status. The majority of patients were male and nearly all mechanical circulatory support devices were left-ventricular assistance devices}{table.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Number (percent) of missing values for a selection of predictor variables in the overall population and in subgroups based on event status. Many predictor variables exhibited similar proportions of missing values in different outcome groups, but surgery time was an exception.}}{15}{table.2}\protected@file@percent }
\newlabel{tbl_missingness}{{2}{15}{Number (percent) of missing values for a selection of predictor variables in the overall population and in subgroups based on event status. Many predictor variables exhibited similar proportions of missing values in different outcome groups, but surgery time was an exception}{table.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Accuracy of strategies to impute artificial missing data. Table values are the median change in accuracy (25th, 75th percentile) relative to the accuracy of imputation to the mean. In general, multiple imputation strategies had lower accuracy than single imputation strategies, and few imputation strategies were more accurate than imputation to the mean.}}{16}{table.3}\protected@file@percent }
\newlabel{tbl_impute_accuracy}{{3}{16}{Accuracy of strategies to impute artificial missing data. Table values are the median change in accuracy (25th, 75th percentile) relative to the accuracy of imputation to the mean. In general, multiple imputation strategies had lower accuracy than single imputation strategies, and few imputation strategies were more accurate than imputation to the mean}{table.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Median (25th, 75th percentile) change in scaled Brier score when different imputation strategies were applied to training and testing sets instead of imputation to the mean prior to developing a risk prediction model for mortality. Table values show the scaled Brier score for imputation to the mean. For other imputation strategies, table values show the change in scaled Brier score relative to the scaled Brier score when imputation to the mean was applied. All table values are multiplied by 100 for ease of interpretability. Multiple imputation with random forests leads to the highest scaled Brier score for both models and when 0\%, 15\%, or 30\% of additional data in the training and testing sets were set to missing.}}{17}{table.4}\protected@file@percent }
\newlabel{tbl_md_strat_dead_ipa}{{4}{17}{Median (25th, 75th percentile) change in scaled Brier score when different imputation strategies were applied to training and testing sets instead of imputation to the mean prior to developing a risk prediction model for mortality. Table values show the scaled Brier score for imputation to the mean. For other imputation strategies, table values show the change in scaled Brier score relative to the scaled Brier score when imputation to the mean was applied. All table values are multiplied by 100 for ease of interpretability. Multiple imputation with random forests leads to the highest scaled Brier score for both models and when 0\%, 15\%, or 30\% of additional data in the training and testing sets were set to missing}{table.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Median (25th, 75th percentile) change in scaled Brier score when different imputation strategies were applied to training and testing sets instead of imputation to the mean prior to developing a risk prediction model for transplant. Table values show the scaled Brier score for imputation to the mean. For other imputation strategies, table values show the change in scaled Brier score relative to the scaled Brier score when imputation to the mean was applied. All table values are multiplied by 100 for ease of interpretability. While there was very little difference in scaled Brier score values when 0\% of additional data were set to missing in the training and testing sets, missingness incorporated as an attribute, predictive mean matching, random forests, and Bayesian regression provided models with higher scaled Brier scores when 15\% or 30\% of additional missing data were amputed.}}{18}{table.5}\protected@file@percent }
\newlabel{tbl_md_strat_txpl_ipa}{{5}{18}{Median (25th, 75th percentile) change in scaled Brier score when different imputation strategies were applied to training and testing sets instead of imputation to the mean prior to developing a risk prediction model for transplant. Table values show the scaled Brier score for imputation to the mean. For other imputation strategies, table values show the change in scaled Brier score relative to the scaled Brier score when imputation to the mean was applied. All table values are multiplied by 100 for ease of interpretability. While there was very little difference in scaled Brier score values when 0\% of additional data were set to missing in the training and testing sets, missingness incorporated as an attribute, predictive mean matching, random forests, and Bayesian regression provided models with higher scaled Brier scores when 15\% or 30\% of additional missing data were amputed}{table.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Median (25th, 75th percentile) change in concordance index when different imputation strategies were applied to training and testing sets instead of imputation to the mean prior to developing a risk prediction model for mortality. Table values show the concordance index for imputation to the mean. For other imputation strategies, table values show the change in concordance index relative to the concordance index when imputation to the mean was applied. All table values are multiplied by 100 for ease of interpretability. Multiple imputation with random forests led to the highest concordance index for boosting models when 0\%, 15\%, or 30\% of additional data in the training and testing sets were set to missing. For proportional hazards models, multiple imputation with nearest neighbors or random forests was the most effective strategy.}}{19}{table.6}\protected@file@percent }
\newlabel{tbl_md_strat_dead_auc}{{6}{19}{Median (25th, 75th percentile) change in concordance index when different imputation strategies were applied to training and testing sets instead of imputation to the mean prior to developing a risk prediction model for mortality. Table values show the concordance index for imputation to the mean. For other imputation strategies, table values show the change in concordance index relative to the concordance index when imputation to the mean was applied. All table values are multiplied by 100 for ease of interpretability. Multiple imputation with random forests led to the highest concordance index for boosting models when 0\%, 15\%, or 30\% of additional data in the training and testing sets were set to missing. For proportional hazards models, multiple imputation with nearest neighbors or random forests was the most effective strategy}{table.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Median (25th, 75th percentile) change in calibration error when different imputation strategies were applied to training and testing sets instead of imputation to the mean prior to developing a risk prediction model for mortality. Table values show the calibration error for imputation to the mean. For other imputation strategies, table values show the change in calibration error relative to the calibration error when imputation to the mean was applied. All table values are multiplied by 100 for ease of interpretability. As more data in the training and testing sets were set to missing, single and multiple imputation with random forests emerged as the strategies with the lowest calibration error.}}{20}{table.7}\protected@file@percent }
\newlabel{tbl_md_strat_dead_cal_error}{{7}{20}{Median (25th, 75th percentile) change in calibration error when different imputation strategies were applied to training and testing sets instead of imputation to the mean prior to developing a risk prediction model for mortality. Table values show the calibration error for imputation to the mean. For other imputation strategies, table values show the change in calibration error relative to the calibration error when imputation to the mean was applied. All table values are multiplied by 100 for ease of interpretability. As more data in the training and testing sets were set to missing, single and multiple imputation with random forests emerged as the strategies with the lowest calibration error}{table.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Median (25th, 75th percentile) change in concordance index when different imputation strategies were applied to training and testing sets instead of imputation to the mean prior to developing a risk prediction model for transplant. Table values show the concordance index for imputation to the mean. For other imputation strategies, table values show the change in concordance index relative to the concordance index when imputation to the mean was applied. All table values are multiplied by 100 for ease of interpretability. While there was very little difference in concordance index when 0\% of additional data were set to missing in the training and testing sets, missingness incorporated as an attribute, predictive mean matching, random forests, and Bayesian regression provided models with higher concordance indices when 15\% or 30\% of additional missing data were amputed.}}{21}{table.8}\protected@file@percent }
\newlabel{tbl_md_strat_txpl_auc}{{8}{21}{Median (25th, 75th percentile) change in concordance index when different imputation strategies were applied to training and testing sets instead of imputation to the mean prior to developing a risk prediction model for transplant. Table values show the concordance index for imputation to the mean. For other imputation strategies, table values show the change in concordance index relative to the concordance index when imputation to the mean was applied. All table values are multiplied by 100 for ease of interpretability. While there was very little difference in concordance index when 0\% of additional data were set to missing in the training and testing sets, missingness incorporated as an attribute, predictive mean matching, random forests, and Bayesian regression provided models with higher concordance indices when 15\% or 30\% of additional missing data were amputed}{table.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Median (25th, 75th percentile) change in calibration error when different imputation strategies were applied to training and testing sets instead of imputation to the mean prior to developing a risk prediction model for transplant. Table values show the calibration error for imputation to the mean. For other imputation strategies, table values show the change in calibration error relative to the calibration error when imputation to the mean was applied. All table values are multiplied by 100 for ease of interpretability. As more data in the training and testing sets were set to missing, single and multiple imputation with nearest neighbors emerged as the optimal strategy for proportional hazards models while missingness incorporated as an attributed emerged an the optimal strategy for boosting models.}}{22}{table.9}\protected@file@percent }
\newlabel{tbl_md_strat_txpl_cal_error}{{9}{22}{Median (25th, 75th percentile) change in calibration error when different imputation strategies were applied to training and testing sets instead of imputation to the mean prior to developing a risk prediction model for transplant. Table values show the calibration error for imputation to the mean. For other imputation strategies, table values show the change in calibration error relative to the calibration error when imputation to the mean was applied. All table values are multiplied by 100 for ease of interpretability. As more data in the training and testing sets were set to missing, single and multiple imputation with nearest neighbors emerged as the optimal strategy for proportional hazards models while missingness incorporated as an attributed emerged an the optimal strategy for boosting models}{table.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces An upset plot showing three variables from the INTERMACS registry and all combinations of missing patterns. The bottom left plot shows the number of missing values for each variable, separately. The top right plot shows the number of missing values for each combination of the three variables. For example, there were 2,618 rows in the overall INTERMACS data where both CV pressure and surgery time were missing.}}{23}{figure.1}\protected@file@percent }
\newlabel{fig:upset}{{1}{23}{An upset plot showing three variables from the INTERMACS registry and all combinations of missing patterns. The bottom left plot shows the number of missing values for each variable, separately. The top right plot shows the number of missing values for each combination of the three variables. For example, there were 2,618 rows in the overall INTERMACS data where both CV pressure and surgery time were missing}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Posterior distribution of differences in scaled Brier score values relative to imputation to the mean when different imputation strategies are applied before fitting a risk prediction model. Results are aggregated over scenarios where the outcome is mortality and transplant and the amount of additional missing data is 0\%, 15\%, or 30\%. Posterior probability that the difference in scaled Brier score exceeds 0, indicating an improvement in overall model accuracy, is printed to the right of each distribution. Each multiple imputation strategy and single imputation with missingness incorporated as an attribute had over 90\% posterior predicted probability of increasing the scaled Brier score versus using imputation to the mean.}}{24}{figure.2}\protected@file@percent }
\newlabel{fig:fig_md_strat_infer_ipa}{{2}{24}{Posterior distribution of differences in scaled Brier score values relative to imputation to the mean when different imputation strategies are applied before fitting a risk prediction model. Results are aggregated over scenarios where the outcome is mortality and transplant and the amount of additional missing data is 0\%, 15\%, or 30\%. Posterior probability that the difference in scaled Brier score exceeds 0, indicating an improvement in overall model accuracy, is printed to the right of each distribution. Each multiple imputation strategy and single imputation with missingness incorporated as an attribute had over 90\% posterior predicted probability of increasing the scaled Brier score versus using imputation to the mean}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Posterior distribution of differences in concordance index values relative to imputation to the mean when different imputation strategies are applied before fitting a risk prediction model. Results are aggregated over scenarios where the outcome is mortality and transplant and the amount of additional missing data is 0\%, 15\%, or 30\%. Posterior probability that the difference in concordance index exceeds 0, indicating an improvement in model discrimination, is printed to the right of each distribution. Multiple imputation with predictive mean matching, random forests, and Bayesian regression each had over 90\% posterior predicted probability of increasing the concordance index versus using imputation to the mean.}}{25}{figure.3}\protected@file@percent }
\newlabel{fig:fig_md_strat_infer_auc}{{3}{25}{Posterior distribution of differences in concordance index values relative to imputation to the mean when different imputation strategies are applied before fitting a risk prediction model. Results are aggregated over scenarios where the outcome is mortality and transplant and the amount of additional missing data is 0\%, 15\%, or 30\%. Posterior probability that the difference in concordance index exceeds 0, indicating an improvement in model discrimination, is printed to the right of each distribution. Multiple imputation with predictive mean matching, random forests, and Bayesian regression each had over 90\% posterior predicted probability of increasing the concordance index versus using imputation to the mean}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Posterior distribution of differences in calibration error values relative to imputation to the mean when different imputation strategies are applied before fitting a risk prediction model. Results are aggregated over scenarios where the outcome is mortality and transplant and the amount of additional missing data is 0\%, 15\%, or 30\%. Posterior probability that the difference in calibration error is less than 0, indicating an improvement in model calibration, is printed to the right of each distribution. Every imputation strategy evaluated had over 90\% posterior predicted probability of improving model calibration versus using imputation to the mean.}}{26}{figure.4}\protected@file@percent }
\newlabel{fig:fig_md_strat_infer_cal_error}{{4}{26}{Posterior distribution of differences in calibration error values relative to imputation to the mean when different imputation strategies are applied before fitting a risk prediction model. Results are aggregated over scenarios where the outcome is mortality and transplant and the amount of additional missing data is 0\%, 15\%, or 30\%. Posterior probability that the difference in calibration error is less than 0, indicating an improvement in model calibration, is printed to the right of each distribution. Every imputation strategy evaluated had over 90\% posterior predicted probability of improving model calibration versus using imputation to the mean}{figure.4}{}}
\bibstyle{unsrt}
\bibdata{references.bib}
\bibcite{benjamin2017heart}{1}
\bibcite{national2017health}{2}
\bibcite{patel2014contemporary}{3}
\bibcite{slaughter2009advanced}{4}
\bibcite{miller2011left}{5}
\bibcite{stewart2011keeping}{6}
\bibcite{hsich2012should}{7}
\bibcite{cotts2014predictors}{8}
\bibcite{eckman2011survival}{9}
\bibcite{kirklin2017eighth}{10}
\bibcite{kormos2019society}{11}
\bibcite{Adamo950}{12}
\@LN{351}{26}
\@LN{352}{26}
\@LN{353}{26}
\@LN{354}{26}
\@LN{355}{26}
\@LN{356}{26}
\@LN{357}{26}
\@LN{358}{26}
\@LN{359}{26}
\@LN{360}{26}
\@LN{361}{26}
\@LN{362}{26}
\@LN{363}{26}
\@LN{364}{26}
\@LN{365}{26}
\@LN{366}{26}
\@LN{367}{26}
\@LN{368}{26}
\@LN{369}{26}
\@LN{370}{26}
\@LN{371}{26}
\@LN{372}{26}
\@LN{373}{26}
\@LN{374}{26}
\@LN{375}{26}
\@LN{376}{26}
\@LN{377}{26}
\@LN{378}{26}
\@LN{379}{26}
\@LN{380}{26}
\@LN{381}{26}
\bibcite{rubin2004multiple}{13}
\bibcite{van2018flexible}{14}
\bibcite{sterne2009multiple}{15}
\bibcite{van2020rebutting}{16}
\bibcite{hastie2009elements}{17}
\bibcite{kuhn2019feature}{18}
\bibcite{jerez2010missing}{19}
\bibcite{josse2019consistency}{20}
\bibcite{thomas2014pre}{21}
\bibcite{azur2011multiple}{22}
\bibcite{van2006fully}{23}
\bibcite{landerman1997empirical}{24}
\bibcite{chen2000nearest}{25}
\@LN{382}{27}
\@LN{383}{27}
\@LN{384}{27}
\@LN{385}{27}
\@LN{386}{27}
\@LN{387}{27}
\@LN{388}{27}
\@LN{389}{27}
\@LN{390}{27}
\@LN{391}{27}
\@LN{392}{27}
\@LN{393}{27}
\@LN{394}{27}
\@LN{395}{27}
\@LN{396}{27}
\@LN{397}{27}
\@LN{398}{27}
\@LN{399}{27}
\@LN{400}{27}
\@LN{401}{27}
\@LN{402}{27}
\@LN{403}{27}
\@LN{404}{27}
\@LN{405}{27}
\@LN{406}{27}
\@LN{407}{27}
\@LN{408}{27}
\@LN{409}{27}
\@LN{410}{27}
\@LN{411}{27}
\@LN{412}{27}
\@LN{413}{27}
\bibcite{gower}{26}
\bibcite{andridge2010hotdeck}{27}
\bibcite{Breiman2001}{28}
\bibcite{hothorn2006survival}{29}
\bibcite{strobl2007bias}{30}
\bibcite{strobl2008conditional}{31}
\bibcite{ishwaran2008random}{32}
\bibcite{jaeger2019oblique}{33}
\bibcite{twala2009empirical}{34}
\bibcite{ding2010investigation}{35}
\bibcite{james2013introduction}{36}
\bibcite{kleinbaum2010survival}{37}
\bibcite{friedman2001greedy}{38}
\bibcite{chen2016xgboost}{39}
\bibcite{graf1999assessment}{40}
\bibcite{rufibach2010use}{41}
\bibcite{gerds2006consistent}{42}
\@LN{414}{28}
\@LN{415}{28}
\@LN{416}{28}
\@LN{417}{28}
\@LN{418}{28}
\@LN{419}{28}
\@LN{420}{28}
\@LN{421}{28}
\@LN{422}{28}
\@LN{423}{28}
\@LN{424}{28}
\@LN{425}{28}
\@LN{426}{28}
\@LN{427}{28}
\@LN{428}{28}
\@LN{429}{28}
\@LN{430}{28}
\@LN{431}{28}
\@LN{432}{28}
\@LN{433}{28}
\@LN{434}{28}
\@LN{435}{28}
\@LN{436}{28}
\@LN{437}{28}
\@LN{438}{28}
\@LN{439}{28}
\@LN{440}{28}
\@LN{441}{28}
\@LN{442}{28}
\@LN{443}{28}
\@LN{444}{28}
\@LN{445}{28}
\@LN{446}{28}
\bibcite{blackstone1986decomposition}{43}
\bibcite{gerds2014calibration}{44}
\bibcite{gerds2013estimating}{45}
\bibcite{kuhn2013applied}{46}
\bibcite{benavoli2017time}{47}
\bibcite{lex2014upset}{48}
\bibcite{van1995python}{49}
\bibcite{sas2013}{50}
\bibcite{drake}{51}
\bibcite{naniar}{52}
\bibcite{mice}{53}
\bibcite{miceRanger}{54}
\bibcite{table.glue}{55}
\bibcite{tidyverse}{56}
\@LN{447}{29}
\@LN{448}{29}
\@LN{449}{29}
\@LN{450}{29}
\@LN{451}{29}
\@LN{452}{29}
\@LN{453}{29}
\@LN{454}{29}
\@LN{455}{29}
\@LN{456}{29}
\@LN{457}{29}
\@LN{458}{29}
\@LN{459}{29}
\@LN{460}{29}
\@LN{461}{29}
\@LN{462}{29}
\@LN{463}{29}
\@LN{464}{29}
\@LN{465}{29}
\@LN{466}{29}
\@LN{467}{29}
\@LN{468}{29}
\@LN{469}{29}
\@LN{470}{29}
\@LN{471}{29}
\@LN{472}{29}
\@LN{473}{29}
\@LN{474}{29}
\@LN{475}{29}
\@LN{476}{29}
\@LN{477}{29}
\@LN{478}{29}
\bibcite{rstanarm}{57}
\bibcite{tidybayes}{58}
\bibcite{survival}{59}
\bibcite{tidymodels}{60}
\bibcite{riskRegression}{61}
\bibcite{byron_2020_4247449}{62}
\bibcite{cheaha}{63}
\bibcite{hassan2007regression}{64}
\bibcite{nanni2012classifier}{65}
\bibcite{tutz2015improved}{66}
\bibcite{little2013joys}{67}
\bibcite{steele2018machine}{68}
\@LN{479}{30}
\@LN{480}{30}
\@LN{481}{30}
\@LN{482}{30}
\@LN{483}{30}
\@LN{484}{30}
\@LN{485}{30}
\@LN{486}{30}
\@LN{487}{30}
\@LN{488}{30}
\@LN{489}{30}
\@LN{490}{30}
\@LN{491}{30}
\@LN{492}{30}
\@LN{493}{30}
\@LN{494}{30}
\@LN{495}{30}
\@LN{496}{30}
\@LN{497}{30}
\@LN{498}{30}
\@LN{499}{30}
\@LN{500}{30}
\@LN{501}{30}
\@LN{502}{30}
\@LN{503}{30}
\gdef \@abspage@last{31}
